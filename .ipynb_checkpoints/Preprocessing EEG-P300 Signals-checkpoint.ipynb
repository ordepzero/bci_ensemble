{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIRECTORY = \"../DATASETS/bci_competition_3/p300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTED_FILES = ROOT_DIRECTORY+\"/segmented_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These variables are about how the signals was recorded. So, it's dataset dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_CHANNELS = 64\n",
    "INTER_STIMULI_SIZE = 42\n",
    "NUMBER_CHARACTERS = 85\n",
    "NUMBER_TRIALS = 15\n",
    "NUMBER_ROWS_COLUMNS = 12\n",
    "NUMBER_STIMULI = NUMBER_TRIALS * NUMBER_ROWS_COLUMNS #180\n",
    "SIGNAL_FREQUENCY = 240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These variable are about how the signals will be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_BEGIN = 0\n",
    "SEGMENT_SIZE = 160\n",
    "LOWCUT = 0.1\n",
    "HIGHCUT = 10.0\n",
    "FILTER_ORDER = 5\n",
    "DECIMATION_FACTOR = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This variable is to identify if is train/test dataset to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNAL_FILENAME = '_char_filtered_signals.csv'\n",
    "CODE_FILENAME = '_codes.csv'\n",
    "STIMULU_FILENAME = '_stimuli.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining  Variables to Segment Signal Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not is_test_file):\n",
    "    SUBFILES = ['train_A','train_B']\n",
    "\n",
    "    SIGNAL_FILES = [\"/subject_A/Subject_A_Train_Signal.txt\",\"/subject_B/Subject_B_Train_Signal.txt\"]\n",
    "    STIMULUS_TYPE_FILES = [\"/subject_A/Subject_A_Train_StimulusType.txt\",\"/subject_B/Subject_B_Train_StimulusType.txt\"]\n",
    "    STIMULUS_CODE_FILES = [\"/subject_A/Subject_A_Train_StimulusCode.txt\",\"/subject_B/Subject_B_Train_StimulusCode.txt\"]\n",
    "else:\n",
    "    SUBFILES = ['test_A','test_B']\n",
    "\n",
    "    SIGNAL_FILES = [\"/subject_A/Subject_A_Test_Signal.txt\",\"/subject_B/Subject_B_Test_Signal.txt\"]\n",
    "    STIMULUS_CODE_FILES = [\"/subject_A/Subject_A_Test_StimulusCode.txt\",\"/subject_B/Subject_B_Test_StimulusCode.txt\"]\n",
    "    STIMULUS_TYPE_FILES = [\"\",\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebyshev1_filter(signals,lowcut, highcut, order,fs=240):\n",
    "\n",
    "    lowcut = 2 * lowcut / fs\n",
    "    highcut = 2 * highcut /fs   \n",
    "  \n",
    "    b, a = signal.cheby1(order, 0.1,[lowcut, highcut],'bandpass')\n",
    "    \n",
    "    filtered_signals = []\n",
    "    for i in range(len(signals)):\n",
    "        signal_decimated = signal.decimate(signals[i],DECIMATION_FACTOR)\n",
    "        filtered_signals.append(signal.lfilter(b, a, signal_decimated))        \n",
    "\n",
    "    return filtered_signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(file_values):\n",
    "    all_extracted_values = []\n",
    "    for i_char in file_values:\n",
    "        separated_values = []\n",
    "        for i_stimuli in range(0,len(file_values[i_char]),INTER_STIMULI_SIZE):\n",
    "            separated_values.append(file_values[i_char][i_stimuli])\n",
    "            if(len(separated_values) == 180):\n",
    "                break\n",
    "        all_extracted_values.append(separated_values)\n",
    "    return all_extracted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, Selecting Values and Saving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin:\n",
      "2019-06-14 03:58:40.480985\n",
      "0:38:23.201190\n"
     ]
    }
   ],
   "source": [
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "if not os.path.exists(SEGMENTED_FILES):\n",
    "    os.makedirs(SEGMENTED_FILES)\n",
    "\n",
    "for sigs,stims,codes,subfilename in zip(SIGNAL_FILES,STIMULUS_TYPE_FILES,STIMULUS_CODE_FILES,SUBFILES):\n",
    "    sigs_file = pd.read_csv(ROOT_DIRECTORY+sigs, delim_whitespace=True, header=None)\n",
    "    codes_file = pd.read_csv(ROOT_DIRECTORY+codes, delim_whitespace=True, header=None)\n",
    "    \n",
    "    if(not is_test_file):\n",
    "        stims_file = pd.read_csv(ROOT_DIRECTORY+stims, delim_whitespace=True, header=None)\n",
    "    \n",
    "    \n",
    "    count_char = 0\n",
    "    for temp_char in range(0,sigs_file.shape[0],NUMBER_CHANNELS):\n",
    "\n",
    "        temp_signals = sigs_file.iloc[temp_char:(temp_char+NUMBER_CHANNELS)]\n",
    "\n",
    "        # Segmenting signals\n",
    "        segments = []\n",
    "        for temp_index,temp_signal in temp_signals.iterrows():\n",
    "            for i_begin in range(0,len(temp_signal),INTER_STIMULI_SIZE):\n",
    "                segments.append(temp_signal[i_begin+SEGMENT_BEGIN:i_begin+SEGMENT_BEGIN+SEGMENT_SIZE])\n",
    "                if(i_begin >= INTER_STIMULI_SIZE*(NUMBER_STIMULI-1)):\n",
    "                    break\n",
    "\n",
    "        # Filtering segmented signals\n",
    "        sigs_seg_filtered = chebyshev1_filter(segments,LOWCUT, HIGHCUT, FILTER_ORDER,SIGNAL_FREQUENCY)\n",
    "\n",
    "        # Checking the if file exist\n",
    "        folder_to_save = SEGMENTED_FILES+'/'+subfilename\n",
    "        if not os.path.exists(folder_to_save):\n",
    "            os.makedirs(folder_to_save)\n",
    "\n",
    "        pd.DataFrame(sigs_seg_filtered).to_csv(folder_to_save+'/'+str(count_char)+SIGNAL_FILENAME,index=False)\n",
    "        count_char = count_char + 1\n",
    "            \n",
    "    \n",
    "    # Extracting codes values\n",
    "    codes_extracted = extract_values(codes_file)\n",
    "    pd.DataFrame(codes_extracted).to_csv(folder_to_save+'/'+CODE_FILENAME,index=False)\n",
    "    \n",
    "    # Extracting stimuli values\n",
    "    if(not is_test_file):\n",
    "        stimuli_extracted = extract_values(stims_file)\n",
    "        pd.DataFrame(stimuli_extracted).to_csv(folder_to_save+'/'+STIMULU_FILENAME,index=False)\n",
    "\n",
    "    \n",
    "end_time = datetime.datetime.now()\n",
    "print('Begin:')\n",
    "print(begin_time)\n",
    "print(end_time-begin_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Train File Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this test, we will check:\n",
    "1. All files was created\n",
    "2. For each file:\n",
    "    1. Number of rows created\n",
    "    1. Number of values in each row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTED_SIGNAL_SHAPE = (NUMBER_CHANNELS*NUMBER_STIMULI,ceil(SEGMENT_SIZE/DECIMATION_FACTOR))\n",
    "STIMULI_CODE_SHAPE = (NUMBER_CHARACTERS,NUMBER_STIMULI)\n",
    "NUMBER_OF_FILES = NUMBER_CHARACTERS+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for subfile in SUBFILES:\n",
    "    onlyfiles = [f for f in listdir(SEGMENTED_FILES+'/'+subfile) if isfile(join(SEGMENTED_FILES+'/'+subfile, f))]\n",
    "    assert len(onlyfiles) == NUMBER_OF_FILES, 'The number of file on directory '+SEGMENTED_FILES+'/'+subfile+' it\\'s different than expected.'+\\\n",
    "    'The expected is '+str(NUMBER_OF_FILES)+', it was found '+str(len(onlyfiles))+'.'\n",
    "\n",
    "    for each_file in onlyfiles:\n",
    "        if('filtered' in each_file):\n",
    "            temp_file = pd.read_csv(SEGMENTED_FILES+'/'+subfile+'/'+each_file)\n",
    "            assert temp_file.shape == SEGMENTED_SIGNAL_SHAPE, 'The shape on '+each_file+' isn\\'t correct. The expected is '+\\\n",
    "                str(SEGMENTED_SIGNAL_SHAPE)+' and it was found '+str(temp_file.shape)+'.'\n",
    "        else:\n",
    "            temp_file = pd.read_csv(SEGMENTED_FILES+'/'+subfile+'/'+each_file)\n",
    "            assert temp_file.shape == STIMULI_CODE_SHAPE, 'The shape on '+each_file+' isn\\'t correct. The expected is '+\\\n",
    "                str(STIMULI_CODE_SHAPE)+' and it was found '+str(temp_file.shape)+'.'\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceil(SEGMENT_SIZE/DECIMATION_FACTOR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
